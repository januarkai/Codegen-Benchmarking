{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/internal/GridLinesLayout.java:GridLinesLayout:0", "source": "\n\n    private final static float GOLDEN_RATIO_INV = 0.61803398874989f;\n    public final static int DEFAULT_COLOR = Color.argb(160, 255, 255, 255);\n\n    private Grid gridMode;\n    private int gridColor = DEFAULT_COLOR;\n\n    private ColorDrawable horiz;\n    private ColorDrawable vert;\n    private final float width;\n\n    interface DrawCallback {\n        void onDraw(int lines);\n    }\n\n    @VisibleForTesting DrawCallback callback;\n\n    public CLASSTOKEN(@NonNull Context context) {\n        this(context, null);\n    }\n\n    public CLASSTOKEN(@NonNull Context context, @Nullable AttributeSet attrs) {\n        super(context, attrs);\n        horiz = new ColorDrawable(gridColor);\n        vert = new ColorDrawable(gridColor);\n        width = TypedValue.applyDimension(TypedValue.COMPLEX_UNIT_DIP, 0.9f,\n                context.getResources().getDisplayMetrics());\n    }\n\n    @Override\n    protected void onLayout(boolean changed, int left, int top, int right, int bottom) {\n        super.onLayout(changed, left, top, right, bottom);\n        horiz.setBounds(left, 0, right, (int) width);\n        vert.setBounds(0, top, (int) width, bottom);\n    }\n\n    /**\n     * Returns the current grid value.\n     * @return the grid mode\n     */\n    @NonNull\n    public Grid getGridMode() {\n        return gridMode;\n    }\n\n    /**\n     * Sets a new grid value\n     * @param gridMode the new value\n     */\n    public void setGridMode(@NonNull Grid gridMode) {\n        this.gridMode = gridMode;\n        postInvalidate();\n    }\n\n    /**\n     * Returns the current grid color.\n     * @return the grid color\n     */\n    public int getGridColor() {\n        return gridColor;\n    }\n\n    /**\n     * Sets a new grid color.\n     * @param gridColor the new color\n     */\n    public void setGridColor(@ColorInt int gridColor) {\n        this.gridColor = gridColor;\n        horiz.setColor(gridColor);\n        vert.setColor(gridColor);\n        postInvalidate();\n    }\n\n    private int getLineCount() {\n        switch (gridMode) {\n            case OFF: return 0;\n            case DRAW_3X3: return 2;\n            case DRAW_PHI: return 2;\n            case DRAW_4X4: return 3;\n        }\n        return 0;\n    }\n\n    private float getLinePosition(int lineNumber) {\n        int lineCount = getLineCount();\n        if (gridMode == Grid.DRAW_PHI) {\n            // 1 = 2x + GRIx\n            // 1 = x(2+GRI)\n            // x = 1/(2+GRI)\n            float delta = 1f/(2+GOLDEN_RATIO_INV);\n            return lineNumber == 1 ? delta : (1 - delta);\n        } else {\n            return (1f / (lineCount + 1)) * (lineNumber + 1f);\n        }\n    }\n\n    @Override\n    protected void onDraw(@NonNull Canvas canvas) {\n        super.onDraw(canvas);\n        int count = getLineCount();\n        for (int n = 0; n < count; n++) {\n            float pos = getLinePosition(n);\n\n            // Draw horizontal line\n            canvas.translate(0, pos * getHeight());\n            horiz.draw(canvas);\n            canvas.translate(0, - pos * getHeight());\n\n            // Draw vertical line\n            canvas.translate(pos * getWidth(), 0);\n            vert.draw(canvas);\n            canvas.translate(- pos * getWidth(), 0);\n        }\n        if (callback != null) {\n            callback.onDraw(count);\n        }\n    }\n", "target": "grid lines layout"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/internal/OrientationHelper.java:OrientationHelper:0", "source": "\n\n    /**\n     * Receives callback about the orientation changes.\n     */\n    public interface Callback {\n        void onDeviceOrientationChanged(int deviceOrientation);\n        void onDisplayOffsetChanged();\n    }\n\n    private final Handler mHandler = new Handler(Looper.getMainLooper());\n    private final Context mContext;\n    private final Callback mCallback;\n\n    @VisibleForTesting\n    final OrientationEventListener mDeviceOrientationListener;\n    private int mDeviceOrientation = -1;\n\n    @VisibleForTesting\n    final DisplayManager.DisplayListener mDisplayOffsetListener;\n    private int mDisplayOffset = -1;\n    \n    private boolean mEnabled;\n\n    /**\n     * Creates a new orientation helper.\n     * @param context a valid context\n     * @param callback a {@link Callback}\n     */\n    public CLASSTOKEN(@NonNull Context context, @NonNull Callback callback) {\n        mContext = context;\n        mCallback = callback;\n        mDeviceOrientationListener = new OrientationEventListener(context.getApplicationContext(),\n                SensorManager.SENSOR_DELAY_NORMAL) {\n\n            @SuppressWarnings(\"ConstantConditions\")\n            @Override\n            public void onOrientationChanged(int orientation) {\n                int deviceOrientation = 0;\n                if (orientation == OrientationEventListener.ORIENTATION_UNKNOWN) {\n                    deviceOrientation = mDeviceOrientation != -1 ? mDeviceOrientation : 0;\n                } else if (orientation >= 315 || orientation < 45) {\n                    deviceOrientation = 0;\n                } else if (orientation >= 45 && orientation < 135) {\n                    deviceOrientation = 90;\n                } else if (orientation >= 135 && orientation < 225) {\n                    deviceOrientation = 180;\n                } else if (orientation >= 225 && orientation < 315) {\n                    deviceOrientation = 270;\n                }\n\n                if (deviceOrientation != mDeviceOrientation) {\n                    mDeviceOrientation = deviceOrientation;\n                    mCallback.onDeviceOrientationChanged(mDeviceOrientation);\n                }\n            }\n        };\n        if (Build.VERSION.SDK_INT >= 17) {\n            mDisplayOffsetListener = new DisplayManager.DisplayListener() {\n                public void onDisplayAdded(int displayId) { }\n                public void onDisplayRemoved(int displayId) { }\n\n                @Override\n                public void onDisplayChanged(int displayId) {\n                    int oldDisplayOffset = mDisplayOffset;\n                    int newDisplayOffset = findDisplayOffset();\n                    if (newDisplayOffset != oldDisplayOffset) {\n                        mDisplayOffset = newDisplayOffset;\n                        mCallback.onDisplayOffsetChanged();\n                    }\n                }\n            };\n        } else {\n            mDisplayOffsetListener = null;\n        }\n    }\n\n    /**\n     * Enables this listener.\n     */\n    public void enable() {\n        if (mEnabled) return;\n        mEnabled = true;\n        mDisplayOffset = findDisplayOffset();\n        if (Build.VERSION.SDK_INT >= 17) {\n            DisplayManager manager = (DisplayManager)\n                    mContext.getSystemService(Context.DISPLAY_SERVICE);\n            // Without the handler, this can crash if called from a thread without a looper\n            manager.registerDisplayListener(mDisplayOffsetListener, mHandler);\n        }\n        mDeviceOrientationListener.enable();\n    }\n\n    /**\n     * Disables this listener.\n     */\n    public void disable() {\n        if (!mEnabled) return;\n        mEnabled = false;\n        mDeviceOrientationListener.disable();\n        if (Build.VERSION.SDK_INT >= 17) {\n            DisplayManager manager = (DisplayManager)\n                    mContext.getSystemService(Context.DISPLAY_SERVICE);\n            manager.unregisterDisplayListener(mDisplayOffsetListener);\n        }\n        mDisplayOffset = -1;\n        mDeviceOrientation = -1;\n    }\n\n    /**\n     * Returns the current device orientation.\n     * @return device orientation\n     */\n    @SuppressWarnings(\"WeakerAccess\")\n    public int getLastDeviceOrientation() {\n        return mDeviceOrientation;\n    }\n\n    /**\n     * Returns the current display offset.\n     * @return display offset\n     */\n    public int getLastDisplayOffset() {\n        return mDisplayOffset;\n    }\n\n    private int findDisplayOffset() {\n        Display display = ((WindowManager) mContext\n                .getSystemService(Context.WINDOW_SERVICE))\n                .getDefaultDisplay();\n        switch (display.getRotation()) {\n            case Surface.ROTATION_0: return 0;\n            case Surface.ROTATION_90: return 90;\n            case Surface.ROTATION_180: return 180;\n            case Surface.ROTATION_270: return 270;\n            default: return 0;\n        }\n    }\n", "target": "orientation helper"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/picture/Snapshot2PictureRecorder.java:FlashAction:1", "source": "\n\n        @Override\n        protected void onStart(@NonNull ActionHolder holder) {\n            super.onStart(holder);\n            LOG.i(\"CLASSTOKEN:\", \"Parameters locked, opening torch.\");\n            holder.getBuilder(this).set(CaptureRequest.FLASH_MODE,\n                    CaptureRequest.FLASH_MODE_TORCH);\n            holder.getBuilder(this).set(CaptureRequest.CONTROL_AE_MODE,\n                    CaptureRequest.CONTROL_AE_MODE_ON);\n            holder.applyBuilder(this);\n        }\n\n        @Override\n        public void onCaptureCompleted(@NonNull ActionHolder holder,\n                                       @NonNull CaptureRequest request,\n                                       @NonNull TotalCaptureResult result) {\n            super.onCaptureCompleted(holder, request, result);\n            Integer flashState = result.get(CaptureResult.FLASH_STATE);\n            if (flashState == null) {\n                LOG.w(\"CLASSTOKEN:\", \"Waiting flash, but flashState is null!\",\n                        \"Taking snapshot.\");\n                setState(STATE_COMPLETED);\n            } else if (flashState == CaptureResult.FLASH_STATE_FIRED) {\n                LOG.i(\"CLASSTOKEN:\", \"Waiting flash and we have FIRED state!\",\n                        \"Taking snapshot.\");\n                setState(STATE_COMPLETED);\n            } else {\n                LOG.i(\"CLASSTOKEN:\", \"Waiting flash but flashState is\",\n                        flashState, \". Waiting...\");\n            }\n        }\n    ", "target": "flash action"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/filters/LomoishFilter.java:LomoishFilter:0", "source": "\n\n    private final static Random RANDOM = new Random();\n    private final static String FRAGMENT_SHADER = \"#extension GL_OES_EGL_image_external : require\\n\"\n            + \"precision mediump float;\\n\"\n            + \"uniform samplerExternalOES sTexture;\\n\"\n            + \"uniform float stepsizeX;\\n\"\n            + \"uniform float stepsizeY;\\n\"\n            + \"uniform vec2 scale;\\n\"\n            + \"uniform float inv_max_dist;\\n\"\n            + \"vec2 seed;\\n\"\n            + \"float stepsize;\\n\"\n            + \"varying vec2 \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\";\\n\"\n            + \"float rand(vec2 loc) {\\n\"\n            + \"  float theta1 = dot(loc, vec2(0.9898, 0.233));\\n\"\n            + \"  float theta2 = dot(loc, vec2(12.0, 78.0));\\n\"\n            + \"  float value = cos(theta1) * sin(theta2) + sin(theta1) * cos(theta2);\\n\"\n            // keep value of part1 in range: (2^-14 to 2^14).\n            + \"  float temp = mod(197.0 * value, 1.0) + value;\\n\"\n            + \"  float part1 = mod(220.0 * temp, 1.0) + temp;\\n\"\n            + \"  float part2 = value * 0.5453;\\n\"\n            + \"  float part3 = cos(theta1 + theta2) * 0.43758;\\n\"\n            + \"  return fract(part1 + part2 + part3);\\n\"\n            + \"}\\n\"\n            + \"void main() {\\n\"\n            + \"  seed[0] = \" + RANDOM.nextFloat() + \";\\n\"\n            + \"  seed[1] = \" + RANDOM.nextFloat() + \";\\n\"\n            + \"  stepsize = \" + 1.0f / 255.0f + \";\\n\"\n            // sharpen\n            + \"  vec3 nbr_color = vec3(0.0, 0.0, 0.0);\\n\"\n            + \"  vec2 coord;\\n\"\n            + \"  vec4 color = texture2D(sTexture, \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\");\\n\"\n            + \"  coord.x = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\".x - 0.5 * stepsizeX;\\n\"\n            + \"  coord.y = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\".y - stepsizeY;\\n\"\n            + \"  nbr_color += texture2D(sTexture, coord).rgb - color.rgb;\\n\"\n            + \"  coord.x = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\".x - stepsizeX;\\n\"\n            + \"  coord.y = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\".y + 0.5 * stepsizeY;\\n\"\n            + \"  nbr_color += texture2D(sTexture, coord).rgb - color.rgb;\\n\"\n            + \"  coord.x = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\".x + stepsizeX;\\n\"\n            + \"  coord.y = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\".y - 0.5 * stepsizeY;\\n\"\n            + \"  nbr_color += texture2D(sTexture, coord).rgb - color.rgb;\\n\"\n            + \"  coord.x = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\".x + stepsizeX;\\n\"\n            + \"  coord.y = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\".y + 0.5 * stepsizeY;\\n\"\n            + \"  nbr_color += texture2D(sTexture, coord).rgb - color.rgb;\\n\"\n            + \"  vec3 s_color = vec3(color.rgb + 0.3 * nbr_color);\\n\"\n            // cross process\n            + \"  vec3 c_color = vec3(0.0, 0.0, 0.0);\\n\"\n            + \"  float value;\\n\"\n            + \"  if (s_color.r < 0.5) {\\n\"\n            + \"    value = s_color.r;\\n\"\n            + \"  } else {\\n\"\n            + \"    value = 1.0 - s_color.r;\\n\"\n            + \"  }\\n\"\n            + \"  float red = 4.0 * value * value * value;\\n\"\n            + \"  if (s_color.r < 0.5) {\\n\"\n            + \"    c_color.r = red;\\n\"\n            + \"  } else {\\n\"\n            + \"    c_color.r = 1.0 - red;\\n\"\n            + \"  }\\n\"\n            + \"  if (s_color.g < 0.5) {\\n\"\n            + \"    value = s_color.g;\\n\"\n            + \"  } else {\\n\"\n            + \"    value = 1.0 - s_color.g;\\n\"\n            + \"  }\\n\"\n            + \"  float green = 2.0 * value * value;\\n\"\n            + \"  if (s_color.g < 0.5) {\\n\"\n            + \"    c_color.g = green;\\n\"\n            + \"  } else {\\n\"\n            + \"    c_color.g = 1.0 - green;\\n\"\n            + \"  }\\n\"\n            + \"  c_color.b = s_color.b * 0.5 + 0.25;\\n\"\n            // blackwhite\n            + \"  float dither = rand(\"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\" + seed);\\n\"\n            + \"  vec3 xform = clamp((c_color.rgb - 0.15) * 1.53846, 0.0, 1.0);\\n\"\n            + \"  vec3 temp = clamp((color.rgb + stepsize - 0.15) * 1.53846, 0.0, 1.0);\\n\"\n            + \"  vec3 bw_color = clamp(xform + (temp - xform) * (dither - 0.5), 0.0, 1.0);\\n\"\n            // vignette\n            + \"  coord = \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\" - vec2(0.5, 0.5);\\n\"\n            + \"  float dist = length(coord * scale);\\n\"\n            + \"  float lumen = 0.85 / (1.0 + exp((dist * inv_max_dist - 0.73) * 20.0)) + 0.15;\\n\"\n            + \"  gl_FragColor = vec4(bw_color * lumen, color.a);\\n\"\n            + \"}\\n\";\n\n    private int width = 1;\n    private int height = 1;\n\n    private int scaleLocation = -1;\n    private int maxDistLocation = -1;\n    private int stepSizeXLocation = -1;\n    private int stepSizeYLocation = -1;\n\n    public CLASSTOKEN() { }\n\n    @Override\n    public void setSize(int width, int height) {\n        super.setSize(width, height);\n        this.width = width;\n        this.height = height;\n    }\n\n    @NonNull\n    @Override\n    public String getFragmentShader() {\n        return FRAGMENT_SHADER;\n    }\n\n    @Override\n    public void onCreate(int programHandle) {\n        super.onCreate(programHandle);\n        scaleLocation = GLES20.glGetUniformLocation(programHandle, \"scale\");\n        Egloo.checkGlProgramLocation(scaleLocation, \"scale\");\n        maxDistLocation = GLES20.glGetUniformLocation(programHandle, \"inv_max_dist\");\n        Egloo.checkGlProgramLocation(maxDistLocation, \"inv_max_dist\");\n        stepSizeXLocation = GLES20.glGetUniformLocation(programHandle, \"stepsizeX\");\n        Egloo.checkGlProgramLocation(stepSizeXLocation, \"stepsizeX\");\n        stepSizeYLocation = GLES20.glGetUniformLocation(programHandle, \"stepsizeY\");\n        Egloo.checkGlProgramLocation(stepSizeYLocation, \"stepsizeY\");\n    }\n\n    @Override\n    public void onDestroy() {\n        super.onDestroy();\n        scaleLocation = -1;\n        maxDistLocation = -1;\n        stepSizeXLocation = -1;\n        stepSizeYLocation = -1;\n    }\n\n    @Override\n    protected void onPreDraw(long timestampUs, @NonNull float[] transformMatrix) {\n        super.onPreDraw(timestampUs, transformMatrix);\n        float[] scale = new float[2];\n        if (width > height) {\n            scale[0] = 1f;\n            scale[1] = ((float) height) / width;\n        } else {\n            scale[0] = ((float) width) / height;\n            scale[1] = 1f;\n        }\n        float maxDist = ((float) Math.sqrt(scale[0] * scale[0] + scale[1] * scale[1])) * 0.5f;\n        GLES20.glUniform2fv(scaleLocation, 1, scale, 0);\n        Egloo.checkGlError(\"glUniform2fv\");\n        GLES20.glUniform1f(maxDistLocation, 1.0F / maxDist);\n        Egloo.checkGlError(\"glUniform1f\");\n        GLES20.glUniform1f(stepSizeXLocation, 1.0F / width);\n        Egloo.checkGlError(\"glUniform1f\");\n        GLES20.glUniform1f(stepSizeYLocation, 1.0F / height);\n        Egloo.checkGlError(\"glUniform1f\");\n    }\n", "target": "lomoish filter"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/filter/FilterParser.java:FilterParser:0", "source": "\n\n    private Filter filter = null;\n\n    public CLASSTOKEN(@NonNull TypedArray array) {\n        String filterName = array.getString(R.styleable.CameraView_cameraFilter);\n        try {\n            //noinspection ConstantConditions\n            Class<?> filterClass = Class.forName(filterName);\n            filter = (Filter) filterClass.newInstance();\n        } catch (Exception ignore) {\n            filter = new NoFilter();\n        }\n    }\n\n    @NonNull\n    public Filter getFilter() {\n        return filter;\n    }\n", "target": "filter parser"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/markers/MarkerParser.java:MarkerParser:0", "source": "\n\n    private AutoFocusMarker autoFocusMarker = null;\n\n    public CLASSTOKEN(@NonNull TypedArray array) {\n        String autoFocusName = array.getString(R.styleable.CameraView_cameraAutoFocusMarker);\n        if (autoFocusName != null) {\n            try {\n                Class<?> autoFocusClass = Class.forName(autoFocusName);\n                autoFocusMarker = (AutoFocusMarker) autoFocusClass.newInstance();\n            } catch (Exception ignore) { }\n        }\n    }\n\n    @Nullable\n    public AutoFocusMarker getAutoFocusMarker() {\n        return autoFocusMarker;\n    }\n", "target": "marker parser"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/picture/Snapshot2PictureRecorder.java:ResetFlashAction:2", "source": "\n\n        @Override\n        protected void onStart(@NonNull ActionHolder holder) {\n            super.onStart(holder);\n            try {\n                // See Camera2Engine.setFlash() comments: turning TORCH off has bugs and we must do\n                // as follows.\n                LOG.i(\"CLASSTOKEN:\", \"Reverting the flash changes.\");\n                CaptureRequest.Builder builder = holder.getBuilder(this);\n                builder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);\n                builder.set(CaptureRequest.FLASH_MODE, CaptureResult.FLASH_MODE_OFF);\n                holder.applyBuilder(this, builder);\n                builder.set(CaptureRequest.CONTROL_AE_MODE, mOriginalAeMode);\n                builder.set(CaptureRequest.FLASH_MODE, mOriginalFlashMode);\n                holder.applyBuilder(this);\n            } catch (CameraAccessException ignore) {}\n        }\n    ", "target": "reset flash action"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/filters/GrayscaleFilter.java:GrayscaleFilter:0", "source": "\n\n    private final static String FRAGMENT_SHADER = \"#extension GL_OES_EGL_image_external : require\\n\"\n            + \"precision mediump float;\\n\"\n            + \"uniform samplerExternalOES sTexture;\\n\"\n            + \"varying vec2 \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\";\\n\"\n            + \"void main() {\\n\"\n            + \"  vec4 color = texture2D(sTexture, \"+DEFAULT_FRAGMENT_TEXTURE_COORDINATE_NAME+\");\\n\"\n            + \"  float y = dot(color, vec4(0.299, 0.587, 0.114, 0));\\n\"\n            + \"  gl_FragColor = vec4(y, y, y, color.a);\\n\"\n            + \"}\\n\";\n\n    public CLASSTOKEN() { }\n\n    @NonNull\n    @Override\n    public String getFragmentShader() {\n        return FRAGMENT_SHADER;\n    }\n", "target": "grayscale filter"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/filter/SimpleFilter.java:SimpleFilter:0", "source": "\n\n    private final String fragmentShader;\n\n    /**\n     * Creates a new filter with the given fragment shader.\n     * @param fragmentShader a fragment shader\n     */\n    @SuppressWarnings(\"WeakerAccess\")\n    public CLASSTOKEN(@NonNull String fragmentShader) {\n        this.fragmentShader = fragmentShader;\n    }\n\n    @NonNull\n    @Override\n    public String getFragmentShader() {\n        return fragmentShader;\n    }\n\n    @NonNull\n    @Override\n    protected BaseFilter onCopy() {\n        return new CLASSTOKEN(fragmentShader);\n    }\n", "target": "simple filter"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/CameraLogger.java:CameraLogger:0", "source": "\n\n    public final static int LEVEL_VERBOSE = 0;\n    public final static int LEVEL_INFO = 1;\n    public final static int LEVEL_WARNING = 2;\n    public final static int LEVEL_ERROR = 3;\n\n    /**\n     * Interface of integers representing log levels.\n     * @see #LEVEL_VERBOSE\n     * @see #LEVEL_INFO\n     * @see #LEVEL_WARNING\n     * @see #LEVEL_ERROR\n     */\n    @IntDef({LEVEL_VERBOSE, LEVEL_INFO, LEVEL_WARNING, LEVEL_ERROR})\n    @Retention(RetentionPolicy.SOURCE)\n    public @interface LogLevel {}\n\n    /**\n     * A Logger can listen to internal log events\n     * and log them to different providers.\n     * The default logger will simply post to logcat.\n     */\n    public interface Logger {\n\n        /**\n         * Notifies that an internal log event was just triggered.\n         *\n         * @param level the log level\n         * @param tag the log tag\n         * @param message the log message\n         * @param throwable an optional throwable\n         */\n        void log(@LogLevel int level,\n                 @NonNull String tag,\n                 @NonNull String message,\n                 @Nullable Throwable throwable);\n    }\n\n    @VisibleForTesting static String lastMessage;\n    @VisibleForTesting static String lastTag;\n\n    private static int sLevel;\n    private static Set<Logger> sLoggers = new CopyOnWriteArraySet<>();\n\n    @VisibleForTesting static Logger sAndroidLogger = new Logger() {\n        @Override\n        public void log(int level,\n                        @NonNull String tag,\n                        @NonNull String message,\n                        @Nullable Throwable throwable) {\n            switch (level) {\n                case LEVEL_VERBOSE: Log.v(tag, message, throwable); break;\n                case LEVEL_INFO: Log.i(tag, message, throwable); break;\n                case LEVEL_WARNING: Log.w(tag, message, throwable); break;\n                case LEVEL_ERROR: Log.e(tag, message, throwable); break;\n            }\n        }\n    };\n\n    static {\n        setLogLevel(LEVEL_ERROR);\n        sLoggers.add(sAndroidLogger);\n    }\n\n    /**\n     * Creates a CLASSTOKEN that will stream logs into the\n     * internal logs and dispatch them to {@link Logger}s.\n     *\n     * @param tag the logger tag\n     * @return a new CLASSTOKEN\n     */\n    public static CLASSTOKEN create(@NonNull String tag) {\n        return new CLASSTOKEN(tag);\n    }\n\n    /**\n     * Sets the log sLevel for logcat events.\n     *\n     * @see #LEVEL_VERBOSE\n     * @see #LEVEL_INFO\n     * @see #LEVEL_WARNING\n     * @see #LEVEL_ERROR\n     * @param logLevel the desired log sLevel\n     */\n    public static void setLogLevel(@LogLevel int logLevel) {\n        sLevel = logLevel;\n    }\n\n    /**\n     * Registers an external {@link Logger} for log events.\n     * Make sure to unregister using {@link #unregisterLogger(Logger)}.\n     *\n     * @param logger logger to add\n     */\n    @SuppressWarnings(\"WeakerAccess\")\n    public static void registerLogger(@NonNull Logger logger) {\n        sLoggers.add(logger);\n    }\n\n    /**\n     * Unregisters a previously registered {@link Logger} for log events.\n     * This is needed in order to avoid leaks.\n     *\n     * @param logger logger to remove\n     */\n    @SuppressWarnings(\"WeakerAccess\")\n    public static void unregisterLogger(@NonNull Logger logger) {\n        sLoggers.remove(logger);\n    }\n\n    @NonNull\n    private String mTag;\n\n    private CLASSTOKEN(@NonNull String tag) {\n        mTag = tag;\n    }\n\n    private boolean should(int messageLevel) {\n        return sLevel <= messageLevel && sLoggers.size() > 0;\n    }\n\n    /**\n     * Log to the verbose channel.\n     * @param data log contents\n     * @return the log message, if logged\n     */\n    @Nullable\n    public String v(@NonNull Object... data) {\n        return log(LEVEL_VERBOSE, data);\n    }\n\n    /**\n     * Log to the info channel.\n     * @param data log contents\n     * @return the log message, if logged\n     */\n    @Nullable\n    public String i(@NonNull Object... data) {\n        return log(LEVEL_INFO, data);\n    }\n\n    /**\n     * Log to the warning channel.\n     * @param data log contents\n     * @return the log message, if logged\n     */\n    @Nullable\n    public String w(@NonNull Object... data) {\n        return log(LEVEL_WARNING, data);\n    }\n\n    /**\n     * Log to the error channel.\n     * @param data log contents\n     * @return the log message, if logged\n     */\n    @Nullable\n    public String e(@NonNull Object... data) {\n        return log(LEVEL_ERROR, data);\n    }\n\n    @Nullable\n    private String log(@LogLevel int level, @NonNull Object... data) {\n        if (!should(level)) return null;\n\n        StringBuilder message = new StringBuilder();\n        Throwable throwable = null;\n        for (Object object : data) {\n            if (object instanceof Throwable) {\n                throwable = (Throwable) object;\n            }\n            message.append(String.valueOf(object));\n            message.append(\" \");\n        }\n        String string = message.toString().trim();\n        for (Logger logger : sLoggers) {\n            logger.log(level, mTag, string, throwable);\n        }\n        lastMessage = string;\n        lastTag = mTag;\n        return string;\n    }\n", "target": "camera logger"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/gesture/TapGestureFinder.java:TapGestureFinder:0", "source": "\n\n    private GestureDetector mDetector;\n    private boolean mNotify;\n\n    public CLASSTOKEN(@NonNull Controller controller) {\n        super(controller, 1);\n        mDetector = new GestureDetector(controller.getContext(),\n                new GestureDetector.SimpleOnGestureListener() {\n\n            @Override\n            public boolean onSingleTapUp(MotionEvent e) {\n                mNotify = true;\n                setGesture(Gesture.TAP);\n                return true;\n            }\n\n            /*\n            TODO should use onSingleTapConfirmed and enable this.\n            public boolean onDoubleTap(MotionEvent e) {\n                mNotify = true;\n                mType = Gesture.DOUBLE_TAP;\n                return true;\n            } */\n\n            @Override\n            public void onLongPress(MotionEvent e) {\n                mNotify = true;\n                setGesture(Gesture.LONG_TAP);\n            }\n        });\n\n        mDetector.setIsLongpressEnabled(true);\n    }\n\n    @Override\n    protected boolean handleTouchEvent(@NonNull MotionEvent event) {\n        // Reset the mNotify flag on a new gesture.\n        // This is to ensure that the mNotify flag stays on until the\n        // previous gesture ends.\n        if (event.getAction() == MotionEvent.ACTION_DOWN) {\n            mNotify = false;\n        }\n\n        // Let's see if we detect something.\n        mDetector.onTouchEvent(event);\n\n        // Keep notifying CameraView as long as the gesture goes.\n        if (mNotify) {\n            getPoint(0).x = event.getX();\n            getPoint(0).y = event.getY();\n            return true;\n        }\n        return false;\n    }\n\n    @Override\n    public float getValue(float currValue, float minValue, float maxValue) {\n        return 0;\n    }\n\n", "target": "tap gesture finder"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/engine/meter/MeterResetAction.java:MeterResetAction:0", "source": "\n\n    private final BaseAction action;\n\n    public CLASSTOKEN() {\n        this.action = Actions.together(\n                new ExposureReset(),\n                new FocusReset(),\n                new WhiteBalanceReset()\n        );\n    }\n\n    @NonNull\n    @Override\n    public BaseAction getAction() {\n        return action;\n    }\n", "target": "meter reset action"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/video/encoding/MediaEncoderEngine.java:Controller:1", "source": "\n\n        /**\n         * Request that the muxer should start. This is not guaranteed to be executed:\n         * we wait for all encoders to call this method, and only then, start the muxer.\n         * @param format the media format\n         * @return the encoder track index\n         */\n        public int notifyStarted(@NonNull MediaFormat format) {\n            synchronized (mControllerLock) {\n                if (mMediaMuxerStarted) {\n                    throw new IllegalStateException(\"Trying to start but muxer started already\");\n                }\n                int track = mMediaMuxer.addTrack(format);\n                LOG.w(\"notifyStarted:\", \"Assigned track\", track, \"to format\",\n                        format.getString(MediaFormat.KEY_MIME));\n                if (++mStartedEncodersCount == mEncoders.size()) {\n                    LOG.w(\"notifyStarted:\", \"All encoders have started.\",\n                            \"Starting muxer and dispatching onEncodingStart().\");\n                    // Go out of this thread since it might be very important for the\n                    // encoders and we don't want to perform expensive operations here.\n                    mControllerThread.run(new Runnable() {\n                        @Override\n                        public void run() {\n                            mMediaMuxer.start();\n                            mMediaMuxerStarted = true;\n                            if (mListener != null) {\n                                mListener.onEncodingStart();\n                            }\n                        }\n                    });\n                }\n                return track;\n            }\n        }\n\n        /**\n         * Whether the muxer is started. MediaEncoders are required to avoid\n         * calling {@link #write(OutputBufferPool, OutputBuffer)} until this method returns true.\n         *\n         * @return true if muxer was started\n         */\n        public boolean isStarted() {\n            synchronized (mControllerLock) {\n                return mMediaMuxerStarted;\n            }\n        }\n\n        @SuppressLint(\"UseSparseArrays\")\n        private Map<Integer, Integer> mDebugCount = new HashMap<>();\n\n        /**\n         * Writes the given data to the muxer. Should be called after {@link #isStarted()}\n         * returns true. Note: this seems to be thread safe, no lock.\n         *\n         * TODO: Skip first frames from encoder A when encoder B reported a firstTimeMillis\n         * time that is significantly later. This can happen even if we wait for both to start,\n         * because {@link MediaEncoder#notifyFirstFrameMillis(long)} can be called while the\n         * muxer is still closed.\n         *\n         * The firstFrameMillis still has a value in computing the absolute times, but it is meant\n         * to be the time of the first frame read, not necessarily a frame that will be written.\n         *\n         * This controller should coordinate between firstFrameMillis and skip frames that have\n         * large differences.\n         *\n         * @param pool pool\n         * @param buffer buffer\n         */\n        public void write(@NonNull OutputBufferPool pool, @NonNull OutputBuffer buffer) {\n            if (DEBUG_PERFORMANCE) {\n                // When AUDIO = mono, this is called about twice the time. (200 vs 100 for 5 sec).\n                Integer count = mDebugCount.get(buffer.trackIndex);\n                mDebugCount.put(buffer.trackIndex, count == null ? 1 : ++count);\n                Calendar calendar = Calendar.getInstance();\n                calendar.setTimeInMillis(buffer.info.presentationTimeUs / 1000);\n                LOG.v(\"write:\", \"Writing into muxer -\",\n                                \"track:\", buffer.trackIndex,\n                        \"presentation:\", buffer.info.presentationTimeUs,\n                        \"readable:\", calendar.get(Calendar.SECOND) + \":\"\n                                + calendar.get(Calendar.MILLISECOND),\n                        \"count:\", count);\n            } else {\n                LOG.v(\"write:\", \"Writing into muxer -\",\n                        \"track:\", buffer.trackIndex,\n                        \"presentation:\", buffer.info.presentationTimeUs);\n            }\n            mMediaMuxer.writeSampleData(buffer.trackIndex, buffer.data, buffer.info);\n            pool.recycle(buffer);\n        }\n\n        /**\n         * Requests that the engine stops. This is not executed until all encoders call\n         * this method, so it is a kind of soft request, just like\n         * {@link #notifyStarted(MediaFormat)}. To be used when maxLength / maxSize constraints\n         * are reached, for example.\n         * When this succeeds, {@link MediaEncoder#stop()} is called.\n         *\n         * @param track track\n         */\n        public void requestStop(int track) {\n            synchronized (mControllerLock) {\n                LOG.w(\"requestStop:\", \"Called for track\", track);\n                if (--mStartedEncodersCount == 0) {\n                    LOG.w(\"requestStop:\", \"All encoders have requested a stop.\",\n                            \"Stopping them.\");\n                    mEndReason = mPossibleEndReason;\n                    // Go out of this thread since it might be very important for the\n                    // encoders and we don't want to perform expensive operations here.\n                    mControllerThread.run(new Runnable() {\n                        @Override\n                        public void run() {\n                            stop();\n                        }\n                    });\n                }\n            }\n        }\n\n        /**\n         * Notifies that the encoder was stopped. After this is called by all encoders,\n         * we will actually stop the muxer.\n         *\n         * @param track track\n         */\n        public void notifyStopped(int track) {\n            synchronized (mControllerLock) {\n                LOG.w(\"notifyStopped:\", \"Called for track\", track);\n                if (++mStoppedEncodersCount == mEncoders.size()) {\n                    LOG.w(\"requestStop:\", \"All encoders have been stopped.\",\n                            \"Stopping the muxer.\");\n                    // Go out of this thread since it might be very important for the\n                    // encoders and we don't want to perform expensive operations here.\n                    mControllerThread.run(new Runnable() {\n                        @Override\n                        public void run() {\n                            end();\n                        }\n                    });\n                }\n            }\n        }\n    ", "target": "controller"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/engine/options/Camera2Options.java:Camera2Options:0", "source": "\n\n    public CLASSTOKEN(@NonNull CameraManager manager,\n                          @NonNull String cameraId,\n                          boolean flipSizes,\n                          int pictureFormat) throws CameraAccessException {\n        Camera2Mapper mapper = Camera2Mapper.get();\n        CameraCharacteristics cameraCharacteristics = manager.getCameraCharacteristics(cameraId);\n\n        // Facing\n        for (String cameraId1 : manager.getCameraIdList()) {\n            CameraCharacteristics cameraCharacteristics1 = manager\n                    .getCameraCharacteristics(cameraId1);\n            Integer cameraFacing = cameraCharacteristics1.get(LENS_FACING);\n            if (cameraFacing != null) {\n                Facing value = mapper.unmapFacing(cameraFacing);\n                if (value != null) supportedFacing.add(value);\n            }\n        }\n\n        // WB\n        int[] awbModes = cameraCharacteristics.get(CONTROL_AWB_AVAILABLE_MODES);\n        //noinspection ConstantConditions\n        for (int awbMode : awbModes) {\n            WhiteBalance value = mapper.unmapWhiteBalance(awbMode);\n            if (value != null) supportedWhiteBalance.add(value);\n        }\n\n        // Flash\n        supportedFlash.add(Flash.OFF);\n        Boolean hasFlash = cameraCharacteristics.get(FLASH_INFO_AVAILABLE);\n        if (hasFlash != null && hasFlash) {\n            int[] aeModes = cameraCharacteristics.get(CONTROL_AE_AVAILABLE_MODES);\n            //noinspection ConstantConditions\n            for (int aeMode : aeModes) {\n                Set<Flash> flashes = mapper.unmapFlash(aeMode);\n                supportedFlash.addAll(flashes);\n            }\n        }\n\n        // HDR\n        supportedHdr.add(Hdr.OFF);\n        int[] sceneModes = cameraCharacteristics.get(CONTROL_AVAILABLE_SCENE_MODES);\n        //noinspection ConstantConditions\n        for (int sceneMode : sceneModes) {\n            Hdr value = mapper.unmapHdr(sceneMode);\n            if (value != null) supportedHdr.add(value);\n        }\n\n        // Zoom\n        Float maxZoom = cameraCharacteristics.get(SCALER_AVAILABLE_MAX_DIGITAL_ZOOM);\n        if(maxZoom != null) {\n            zoomSupported = maxZoom > 1;\n        }\n\n\n        // AutoFocus\n        // This now means 3A metering with respect to a specific region of the screen.\n        // Some controls (AF, AE) have special triggers that might or might not be supported.\n        // But they can also be on some continuous search mode so that the trigger is not needed.\n        // What really matters in my opinion is the availability of regions.\n        Integer afRegions = cameraCharacteristics.get(CONTROL_MAX_REGIONS_AF);\n        Integer aeRegions = cameraCharacteristics.get(CONTROL_MAX_REGIONS_AE);\n        Integer awbRegions = cameraCharacteristics.get(CONTROL_MAX_REGIONS_AWB);\n        autoFocusSupported = (afRegions != null && afRegions > 0)\n                || (aeRegions != null && aeRegions > 0)\n                || (awbRegions != null && awbRegions > 0);\n\n        // Exposure correction\n        Range<Integer> exposureRange = cameraCharacteristics.get(CONTROL_AE_COMPENSATION_RANGE);\n        Rational exposureStep = cameraCharacteristics.get(CONTROL_AE_COMPENSATION_STEP);\n        if (exposureRange != null && exposureStep != null && exposureStep.floatValue() != 0) {\n            exposureCorrectionMinValue = exposureRange.getLower() / exposureStep.floatValue();\n            exposureCorrectionMaxValue = exposureRange.getUpper() / exposureStep.floatValue();\n        }\n        exposureCorrectionSupported = exposureCorrectionMinValue != 0\n                && exposureCorrectionMaxValue != 0;\n\n\n        // Picture Sizes\n        StreamConfigurationMap streamMap = cameraCharacteristics.get(\n                SCALER_STREAM_CONFIGURATION_MAP);\n        if (streamMap == null) {\n            throw new RuntimeException(\"StreamConfigurationMap is null. Should not happen.\");\n        }\n        int[] pictureFormats = streamMap.getOutputFormats();\n        boolean hasPictureFormat = false;\n        for (int picFormat : pictureFormats) {\n            if (picFormat == pictureFormat) {\n                hasPictureFormat = true;\n                break;\n            }\n        }\n        if (!hasPictureFormat) {\n            throw new IllegalStateException(\"Picture format not supported: \" + pictureFormat);\n        }\n        android.util.Size[] psizes = streamMap.getOutputSizes(pictureFormat);\n        for (android.util.Size size : psizes) {\n            int width = flipSizes ? size.getHeight() : size.getWidth();\n            int height = flipSizes ? size.getWidth() : size.getHeight();\n            supportedPictureSizes.add(new Size(width, height));\n            supportedPictureAspectRatio.add(AspectRatio.of(width, height));\n        }\n\n        // Video Sizes\n        // As a safety measure, remove Sizes bigger than CamcorderProfile.highest\n        CamcorderProfile profile = CamcorderProfiles.get(cameraId,\n                new Size(Integer.MAX_VALUE, Integer.MAX_VALUE));\n        Size videoMaxSize = new Size(profile.videoFrameWidth, profile.videoFrameHeight);\n        android.util.Size[] vsizes = streamMap.getOutputSizes(MediaRecorder.class);\n        for (android.util.Size size : vsizes) {\n            if (size.getWidth() <= videoMaxSize.getWidth()\n                    && size.getHeight() <= videoMaxSize.getHeight()) {\n                int width = flipSizes ? size.getHeight() : size.getWidth();\n                int height = flipSizes ? size.getWidth() : size.getHeight();\n                supportedVideoSizes.add(new Size(width, height));\n                supportedVideoAspectRatio.add(AspectRatio.of(width, height));\n            }\n        }\n\n        // Preview FPS\n        Range<Integer>[] range = cameraCharacteristics.get(CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES);\n        if (range != null) {\n            previewFrameRateMinValue = Float.MAX_VALUE;\n            previewFrameRateMaxValue = -Float.MAX_VALUE;\n            for (Range<Integer> fpsRange : range) {\n                previewFrameRateMinValue = Math.min(previewFrameRateMinValue, fpsRange.getLower());\n                previewFrameRateMaxValue = Math.max(previewFrameRateMaxValue, fpsRange.getUpper());\n            }\n        } else {\n            previewFrameRateMinValue = 0F;\n            previewFrameRateMaxValue = 0F;\n        }\n\n        // Picture formats\n        supportedPictureFormats.add(PictureFormat.JPEG);\n        int[] caps = cameraCharacteristics.get(REQUEST_AVAILABLE_CAPABILITIES);\n        if (caps != null) {\n            for (int cap : caps) {\n                if (cap == CameraCharacteristics.REQUEST_AVAILABLE_CAPABILITIES_RAW) {\n                    supportedPictureFormats.add(PictureFormat.DNG);\n                }\n            }\n        }\n\n        // Frame processing formats\n        supportedFrameProcessingFormats.add(ImageFormat.YUV_420_888);\n        int[] outputFormats = streamMap.getOutputFormats();\n        for (int outputFormat : outputFormats) {\n            // Ensure it is a raw format\n            if (ImageFormat.getBitsPerPixel(outputFormat) > 0) {\n                supportedFrameProcessingFormats.add(outputFormat);\n            }\n        }\n    }\n", "target": "camera 2 options"}
{"lang": "java", "dataset": "java_ds", "id": "java_ds:dataset/CameraView/cameraview/src/main/java/com/otaliastudios/cameraview/video/VideoRecorder.java:VideoRecorder:0", "source": "\n\n    private final static String TAG = CLASSTOKEN.class.getSimpleName();\n    private final static CameraLogger LOG = CameraLogger.create(TAG);\n\n    /**\n     * Listens for video recorder events.\n     */\n    public interface VideoResultListener {\n\n        /**\n         * The operation was completed, either with success or with an error.\n         * @param result the result or null if error\n         * @param exception the error or null if everything went fine\n         */\n        void onVideoResult(@Nullable VideoResult.Stub result, @Nullable Exception exception);\n\n        /**\n         * The callback for the actual video recording starting.\n         */\n        void onVideoRecordingStart();\n\n        /**\n         * Video recording has ended. We will finish processing the file\n         * and soon {@link #onVideoResult(VideoResult.Stub, Exception)} will be called.\n         */\n        void onVideoRecordingEnd();\n    }\n\n    private final static int STATE_IDLE = 0;\n    private final static int STATE_RECORDING = 1;\n    private final static int STATE_STOPPING = 2;\n\n    @VisibleForTesting(otherwise = VisibleForTesting.PROTECTED) VideoResult.Stub mResult;\n    private final VideoResultListener mListener;\n    @SuppressWarnings(\"WeakerAccess\")\n    protected Exception mError;\n    private int mState;\n    private final Object mStateLock = new Object();\n\n    /**\n     * Creates a new video recorder.\n     * @param listener a listener\n     */\n    CLASSTOKEN(@Nullable VideoResultListener listener) {\n        mListener = listener;\n        mState = STATE_IDLE;\n    }\n\n    /**\n     * Starts recording a video.\n     *\n     * @param stub the video stub\n     */\n    public final void start(@NonNull VideoResult.Stub stub) {\n        synchronized (mStateLock) {\n            if (mState != STATE_IDLE) {\n                LOG.e(\"start:\", \"called twice, or while stopping! \" +\n                        \"Ignoring. state:\", mState);\n                return;\n            }\n            LOG.i(\"start:\", \"Changed state to STATE_RECORDING\");\n            mState = STATE_RECORDING;\n        }\n        mResult = stub;\n        onStart();\n    }\n\n    /**\n     * Stops recording.\n     * @param isCameraShutdown whether this is a full shutdown, camera is being closed\n     */\n    public final void stop(boolean isCameraShutdown) {\n        synchronized (mStateLock) {\n            if (mState == STATE_IDLE) {\n                // Do not check for STOPPING! See onStop().\n                LOG.e(\"stop:\", \"called twice, or called before start! \" +\n                        \"Ignoring. isCameraShutdown:\", isCameraShutdown);\n                return;\n            }\n            LOG.i(\"stop:\", \"Changed state to STATE_STOPPING\");\n            mState = STATE_STOPPING;\n        }\n        onStop(isCameraShutdown);\n    }\n\n    /**\n     * Returns true if it is currently recording.\n     * @return true if recording\n     */\n    public boolean isRecording() {\n        // true if not idle.\n        synchronized (mStateLock) {\n            return mState != STATE_IDLE;\n        }\n    }\n\n    protected abstract void onStart();\n\n    /**\n     * Should stop recording as fast as possible. This can be called twice because the\n     * shutdown boolean might be different.\n     *\n     * @param isCameraShutdown whether camera is shutting down\n     */\n    protected abstract void onStop(boolean isCameraShutdown);\n\n    /**\n     * Subclasses can call this to notify that the result was obtained,\n     * either with some error (null result) or with the actual stub, filled.\n     */\n    protected final void dispatchResult() {\n        synchronized (mStateLock) {\n            if (!isRecording()) {\n                LOG.w(\"dispatchResult:\", \"Called, but not recording! Aborting.\");\n                return;\n            }\n            LOG.i(\"dispatchResult:\", \"Changed state to STATE_IDLE.\");\n            mState = STATE_IDLE;\n        }\n        onDispatchResult();\n        LOG.i(\"dispatchResult:\", \"About to dispatch result:\", mResult, mError);\n        if (mListener != null) {\n            mListener.onVideoResult(mResult, mError);\n        }\n        mResult = null;\n        mError = null;\n    }\n\n    /**\n     * Subclasses can override this to release resources.\n     */\n    protected void onDispatchResult() {\n        // No-op\n    }\n\n    /**\n     * Subclasses can call this to notify that the video recording has started,\n     * this will be called when camera is prepared and started.\n     */\n    @SuppressWarnings(\"WeakerAccess\")\n    @CallSuper\n    protected void dispatchVideoRecordingStart() {\n        LOG.i(\"dispatchVideoRecordingStart:\", \"About to dispatch.\");\n        if (mListener != null) {\n            mListener.onVideoRecordingStart();\n        }\n    }\n\n    /**\n     * Subclasses can call this to notify that the video recording has ended,\n     * although the video result might still be processed.\n     */\n    @SuppressWarnings(\"WeakerAccess\")\n    @CallSuper\n    protected void dispatchVideoRecordingEnd() {\n        LOG.i(\"dispatchVideoRecordingEnd:\", \"About to dispatch.\");\n        if (mListener != null) {\n            mListener.onVideoRecordingEnd();\n        }\n    }\n", "target": "video recorder"}
